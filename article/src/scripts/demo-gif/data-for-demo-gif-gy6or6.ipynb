{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb4382d-da6e-4720-9021-618413e7b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import crowsetta\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyprojroot\n",
    "from tqdm import tqdm\n",
    "import torch.utils.data\n",
    "\n",
    "import vak\n",
    "from vak import (\n",
    "    config,\n",
    "    constants,\n",
    "    core,\n",
    "    files,\n",
    "    io,\n",
    "    labeled_timebins,\n",
    "    logging,\n",
    ")\n",
    "from vak.logging import log_or_print\n",
    "from vak import models\n",
    "from vak import transforms\n",
    "from vak.datasets import VocalDataset\n",
    "from vak.device import get_default as get_default_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e56b5b7-d58b-4dd9-aa96-170bf9fdec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_core(\n",
    "    csv_path,\n",
    "    checkpoint_path,\n",
    "    labelmap_path,\n",
    "    model_config_map,\n",
    "    window_size,\n",
    "    num_workers=2,\n",
    "    spect_key=\"s\",\n",
    "    timebins_key=\"t\",\n",
    "    spect_scaler_path=None,\n",
    "    device=None,\n",
    "    annot_csv_filename=None,\n",
    "    min_segment_dur=None,\n",
    "    majority_vote=False,\n",
    "    save_net_outputs=False,\n",
    "    logger=None,\n",
    "):\n",
    "    \"\"\"make predictions on dataset with trained model specified in config.toml file.\n",
    "\n",
    "    copied/adapted from `vak` -- returns predictions instead of saving them.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = get_default_device()\n",
    "\n",
    "    # ---------------- load data for prediction ------------------------------------------------------------------------\n",
    "    if spect_scaler_path:\n",
    "        log_or_print(\n",
    "            f\"loading SpectScaler from path: {spect_scaler_path}\",\n",
    "            logger=logger,\n",
    "            level=\"info\",\n",
    "        )\n",
    "        spect_standardizer = joblib.load(spect_scaler_path)\n",
    "    else:\n",
    "        log_or_print(\n",
    "            f\"Not loading SpectScaler, no path was specified\",\n",
    "            logger=logger,\n",
    "            level=\"info\",\n",
    "        )\n",
    "        spect_standardizer = None\n",
    "\n",
    "    item_transform = transforms.get_defaults(\n",
    "        \"predict\",\n",
    "        spect_standardizer,\n",
    "        window_size=window_size,\n",
    "        return_padding_mask=True,\n",
    "    )\n",
    "\n",
    "    log_or_print(\n",
    "        f\"loading labelmap from path: {labelmap_path}\", logger=logger, level=\"info\"\n",
    "    )\n",
    "    with labelmap_path.open(\"r\") as f:\n",
    "        labelmap = json.load(f)\n",
    "\n",
    "    log_or_print(\n",
    "        f\"loading dataset to predict from csv path: {csv_path}\",\n",
    "        logger=logger,\n",
    "        level=\"info\",\n",
    "    )\n",
    "    pred_dataset = VocalDataset.from_csv(\n",
    "        csv_path=csv_path,\n",
    "        split=\"predict\",\n",
    "        labelmap=labelmap,\n",
    "        spect_key=spect_key,\n",
    "        timebins_key=timebins_key,\n",
    "        item_transform=item_transform,\n",
    "    )\n",
    "\n",
    "    pred_data = torch.utils.data.DataLoader(\n",
    "        dataset=pred_dataset,\n",
    "        shuffle=False,\n",
    "        # batch size 1 because each spectrogram reshaped into a batch of windows\n",
    "        batch_size=1,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    # ---------------- set up to convert predictions to annotation files -----------------------------------------------\n",
    "    if annot_csv_filename is None:\n",
    "        annot_csv_filename = Path(csv_path).stem + constants.ANNOT_CSV_SUFFIX\n",
    "    annot_csv_path = Path('.') / 'dummy-filename.csv'  # not really used\n",
    "    log_or_print(\n",
    "        f\"will save annotations in .csv file: {annot_csv_path}\",\n",
    "        logger=logger,\n",
    "        level=\"info\",\n",
    "    )\n",
    "\n",
    "    dataset_df = pd.read_csv(csv_path)\n",
    "    timebin_dur = io.dataframe.validate_and_get_timebin_dur(dataset_df)\n",
    "    log_or_print(\n",
    "        f\"dataset has timebins with duration: {timebin_dur}\",\n",
    "        logger=logger,\n",
    "        level=\"info\",\n",
    "    )\n",
    "\n",
    "    # ---------------- do the actual predicting + converting to annotations --------------------------------------------\n",
    "    input_shape = pred_dataset.shape\n",
    "    # if dataset returns spectrogram reshaped into windows,\n",
    "    # throw out the window dimension; just want to tell network (channels, height, width) shape\n",
    "    if len(input_shape) == 4:\n",
    "        input_shape = input_shape[1:]\n",
    "    log_or_print(\n",
    "        f\"shape of input to networks used for predictions: {input_shape}\",\n",
    "        logger=logger,\n",
    "        level=\"info\",\n",
    "    )\n",
    "\n",
    "    log_or_print(\n",
    "        f\"instantiating models from model-config map:/n{model_config_map}\",\n",
    "        logger=logger,\n",
    "        level=\"info\",\n",
    "    )\n",
    "    models_map = models.from_model_config_map(\n",
    "        model_config_map, num_classes=len(labelmap), input_shape=input_shape\n",
    "    )\n",
    "    for model_name, model in models_map.items():\n",
    "        # ---------------- do the actual predicting --------------------------------------------------------------------\n",
    "        log_or_print(\n",
    "            f\"loading checkpoint for {model_name} from path: {checkpoint_path}\",\n",
    "            logger=logger,\n",
    "            level=\"info\",\n",
    "        )\n",
    "        model.load(checkpoint_path, device=device)\n",
    "        log_or_print(\n",
    "            f\"running predict method of {model_name}\", logger=logger, level=\"info\"\n",
    "        )\n",
    "        pred_dict = model.predict(pred_data=pred_data, device=device)\n",
    "\n",
    "        # ----------------  converting to annotations ------------------------------------------------------------------\n",
    "        progress_bar = tqdm(pred_data)\n",
    "\n",
    "        annots = []\n",
    "        log_or_print(\n",
    "            \"converting predictions to annotations\", logger=logger, level=\"info\"\n",
    "        )\n",
    "        for ind, batch in enumerate(progress_bar):\n",
    "            padding_mask, spect_path = batch[\"padding_mask\"], batch[\"spect_path\"]\n",
    "            padding_mask = np.squeeze(padding_mask)\n",
    "            if isinstance(spect_path, list) and len(spect_path) == 1:\n",
    "                spect_path = spect_path[0]\n",
    "            y_pred = pred_dict[spect_path]\n",
    "\n",
    "            y_pred = torch.argmax(y_pred, dim=1)  # assumes class dimension is 1\n",
    "            y_pred = torch.flatten(y_pred).cpu().numpy()[padding_mask]\n",
    "\n",
    "            spect_dict = files.spect.load(spect_path)\n",
    "            t = spect_dict[timebins_key]\n",
    "            labels, onsets_s, offsets_s = labeled_timebins.lbl_tb2segments(\n",
    "                y_pred,\n",
    "                labelmap=labelmap,\n",
    "                t=t,\n",
    "                min_segment_dur=min_segment_dur,\n",
    "                majority_vote=majority_vote,\n",
    "            )\n",
    "            if labels is None and onsets_s is None and offsets_s is None:\n",
    "                # handle the case when all time bins are predicted to be unlabeled\n",
    "                # see https://github.com/NickleDave/vak/issues/383\n",
    "                continue\n",
    "            seq = crowsetta.Sequence.from_keyword(\n",
    "                labels=labels, onsets_s=onsets_s, offsets_s=offsets_s\n",
    "            )\n",
    "\n",
    "            audio_fname = files.spect.find_audio_fname(spect_path)\n",
    "            annot = crowsetta.Annotation(\n",
    "                seq=seq, audio_path=audio_fname, annot_path=annot_csv_path.name\n",
    "            )\n",
    "            annots.append(annot)\n",
    "        \n",
    "    return pred_dict, annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680652df-3e45-4c5d-a117-4c9347360914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cli(toml_path):\n",
    "    toml_path = Path(toml_path)\n",
    "    cfg = config.parse.from_toml_path(toml_path)\n",
    "\n",
    "    if cfg.predict is None:\n",
    "        raise ValueError(\n",
    "            f\"predict called with a config.toml file that does not have a PREDICT section: {toml_path}\"\n",
    "        )\n",
    "\n",
    "    # ---- set up logging ----------------------------------------------------------------------------------------------\n",
    "    timenow = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "\n",
    "    model_config_map = config.models.map_from_path(toml_path, cfg.predict.models)\n",
    "\n",
    "    pred_dict, annots = predict_core(\n",
    "        csv_path=cfg.predict.csv_path,\n",
    "        checkpoint_path=cfg.predict.checkpoint_path,\n",
    "        labelmap_path=cfg.predict.labelmap_path,\n",
    "        model_config_map=model_config_map,\n",
    "        window_size=cfg.dataloader.window_size,\n",
    "        num_workers=cfg.predict.num_workers,\n",
    "        spect_key=cfg.spect_params.spect_key,\n",
    "        timebins_key=cfg.spect_params.timebins_key,\n",
    "        spect_scaler_path=cfg.predict.spect_scaler_path,\n",
    "        device=cfg.predict.device,\n",
    "        annot_csv_filename=cfg.predict.annot_csv_filename,\n",
    "        min_segment_dur=cfg.predict.min_segment_dur,\n",
    "        majority_vote=cfg.predict.majority_vote,\n",
    "        save_net_outputs=cfg.predict.save_net_outputs,\n",
    "        logger=None,\n",
    "    )\n",
    "\n",
    "    return pred_dict, annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c67f57a8-8425-4b2e-805d-8601379ea88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "toml_path = '/home/art/Documents/repos/coding/birdsong/tweetynet/article/data/configs/demo-gif/gy60r6_predict_032612.toml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dbdeffd-7aed-43e5-a5d9-36a3f8b73500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/art/Documents/repos/coding/birdsong/tweetynet/article\n"
     ]
    }
   ],
   "source": [
    "cd /home/art/Documents/repos/coding/birdsong/tweetynet/article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bec0eb8d-4743-4a5e-bb34-265a9300d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/demo-gif/has_notmat_prep_210612_205945.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1a77048-4c75-4421-a8f5-e8509dd6b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['annot_format'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f2c4e67-d2ce-4f93-8695-a642e931eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/demo-gif/has_notmat_prep_210612_205945.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58b3576e-299b-4955-9229-651e5764b633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading SpectScaler from path: results/Bengalese_Finches/learncurve/gy6or6/results_210509_010443/train_dur_600s/replicate_1/StandardizeSpect\n",
      "loading labelmap from path: results/Bengalese_Finches/learncurve/gy6or6/results_210509_010443/train_dur_600s/replicate_1/labelmap.json\n",
      "loading dataset to predict from csv path: data/demo-gif/has_notmat_prep_210612_205945.csv\n",
      "will save annotations in .csv file: dummy-filename.csv\n",
      "dataset has timebins with duration: 0.002\n",
      "shape of input to networks used for predictions: torch.Size([1, 257, 176])\n",
      "instantiating models from model-config map:/n{'TweetyNet': {'optimizer': {'lr': 0.001}, 'network': {'hidden_size': 256}, 'loss': {}, 'metrics': {}}}\n",
      "loading checkpoint for TweetyNet from path: results/Bengalese_Finches/learncurve/gy6or6/results_210509_010443/train_dur_600s/replicate_1/TweetyNet/checkpoints/max-val-acc-checkpoint.pt\n",
      "Loading checkpoint from:\n",
      "results/Bengalese_Finches/learncurve/gy6or6/results_210509_010443/train_dur_600s/replicate_1/TweetyNet/checkpoints/max-val-acc-checkpoint.pt \n",
      "running predict method of TweetyNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch 38 / 39: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:03<00:00,  9.81it/s]\n",
      "  0%|                                                                                                                                     | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting predictions to annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:01<00:00, 37.63it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_dict, annots = predict_cli(toml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "612c66fb-395e-46b6-b9e9-5da04b13fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {k: v.cpu().numpy() for k, v in pred_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "208c513d-c3f2-435f-bbac-8742f1d790f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/art/Documents/repos/coding/birdsong/tweetynet/article/data/demo-gif/gy60r6_predict_032612.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/home/art/Documents/repos/coding/birdsong/tweetynet/article/data/demo-gif/gy60r6_predict_032612.joblib'\n",
    "value = {\n",
    "    'pred_dict': pred_dict,\n",
    "    'annots': annots\n",
    "}\n",
    "joblib.dump(value, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d052a-cf42-4b4f-bbc2-c0687b2dda03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
