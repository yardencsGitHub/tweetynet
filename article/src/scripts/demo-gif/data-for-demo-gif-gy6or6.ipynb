{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb4382d-da6e-4720-9021-618413e7b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import crowsetta\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyprojroot\n",
    "from tqdm import tqdm\n",
    "import torch.utils.data\n",
    "\n",
    "import vak\n",
    "from vak import (\n",
    "    config,\n",
    "    constants,\n",
    "    core,\n",
    "    files,\n",
    "    io,\n",
    "    labeled_timebins,\n",
    "    logging,\n",
    ")\n",
    "from vak.logging import log_or_print\n",
    "from vak import models\n",
    "from vak import transforms\n",
    "from vak.datasets import VocalDataset\n",
    "from vak.device import get_default as get_default_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e56b5b7-d58b-4dd9-aa96-170bf9fdec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_core(\n",
    "    csv_path,\n",
    "    checkpoint_path,\n",
    "    labelmap_path,\n",
    "    model_config_map,\n",
    "    window_size,\n",
    "    num_workers=2,\n",
    "    spect_key=\"s\",\n",
    "    timebins_key=\"t\",\n",
    "    spect_scaler_path=None,\n",
    "    device=None,\n",
    "    annot_csv_filename=None,\n",
    "    min_segment_dur=None,\n",
    "    majority_vote=False,\n",
    "    save_net_outputs=False,\n",
    "    logger=None,\n",
    "):\n",
    "    \"\"\"make predictions on dataset with trained model specified in config.toml file.\n",
    "\n",
    "    copied/adapted from `vak` -- returns predictions instead of saving them.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = get_default_device()\n",
    "\n",
    "    # ---------------- load data for prediction ------------------------------------------------------------------------\n",
    "    if spect_scaler_path:\n",
    "        log_or_print(\n",
    "            f\"loading SpectScaler from path: {spect_scaler_path}\",\n",
    "            logger=logger,\n",
    "            level=\"info\",\n",
    "        )\n",
    "        spect_standardizer = joblib.load(spect_scaler_path)\n",
    "    else:\n",
    "        log_or_print(\n",
    "            f\"Not loading SpectScaler, no path was specified\",\n",
    "            logger=logger,\n",
    "            level=\"info\",\n",
    "        )\n",
    "        spect_standardizer = None\n",
    "\n",
    "    item_transform = transforms.get_defaults(\n",
    "        \"predict\",\n",
    "        spect_standardizer,\n",
    "        window_size=window_size,\n",
    "        return_padding_mask=True,\n",
    "    )\n",
    "\n",
    "    log_or_print(\n",
    "        f\"loading labelmap from path: {labelmap_path}\", logger=logger, level=\"info\"\n",
    "    )\n",
    "    with labelmap_path.open(\"r\") as f:\n",
    "        labelmap = json.load(f)\n",
    "\n",
    "    log_or_print(\n",
    "        f\"loading dataset to predict from csv path: {csv_path}\",\n",
    "        logger=logger,\n",
    "        level=\"info\",\n",
    "    )\n",
    "    pred_dataset = VocalDataset.from_csv(\n",
    "        csv_path=csv_path,\n",
    "        split=\"predict\",\n",
    "        labelmap=labelmap,\n",
    "        spect_key=spect_key,\n",
    "        timebins_key=timebins_key,\n",
    "        item_transform=item_transform,\n",
    "    )\n",
    "\n",
    "    pred_data = torch.utils.data.DataLoader(\n",
    "        dataset=pred_dataset,\n",
    "        shuffle=False,\n",
    "        # batch size 1 because each spectrogram reshaped into a batch of windows\n",
    "        batch_size=1,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    # ---------------- set up to convert predictions to annotation files -----------------------------------------------\n",
    "    if annot_csv_filename is None:\n",
    "        annot_csv_filename = Path(csv_path).stem + constants.ANNOT_CSV_SUFFIX\n",
    "    annot_csv_path = Path('.') / 'dummy-filename.csv'  # not really used\n",
    "    log_or_print(\n",
    "        f\"will save annotations in .csv file: {annot_csv_path}\",\n",
    "        logger=logger,\n",
    "        level=\"info\",\n",
    "    )\n",
    "\n",
    "    dataset_df = pd.read_csv(csv_path)\n",
    "    timebin_dur = io.dataframe.validate_and_get_timebin_dur(dataset_df)\n",
    "    log_or_print(\n",
    "        f\"dataset has timebins with duration: {timebin_dur}\",\n",
    "        logger=logger,\n",
    "        level=\"info\",\n",
    "    )\n",
    "\n",
    "    # ---------------- do the actual predicting + converting to annotations --------------------------------------------\n",
    "    input_shape = pred_dataset.shape\n",
    "    # if dataset returns spectrogram reshaped into windows,\n",
    "    # throw out the window dimension; just want to tell network (channels, height, width) shape\n",
    "    if len(input_shape) == 4:\n",
    "        input_shape = input_shape[1:]\n",
    "    log_or_print(\n",
    "        f\"shape of input to networks used for predictions: {input_shape}\",\n",
    "        logger=logger,\n",
    "        level=\"info\",\n",
    "    )\n",
    "\n",
    "    log_or_print(\n",
    "        f\"instantiating models from model-config map:/n{model_config_map}\",\n",
    "        logger=logger,\n",
    "        level=\"info\",\n",
    "    )\n",
    "    models_map = models.from_model_config_map(\n",
    "        model_config_map, num_classes=len(labelmap), input_shape=input_shape\n",
    "    )\n",
    "    for model_name, model in models_map.items():\n",
    "        # ---------------- do the actual predicting --------------------------------------------------------------------\n",
    "        log_or_print(\n",
    "            f\"loading checkpoint for {model_name} from path: {checkpoint_path}\",\n",
    "            logger=logger,\n",
    "            level=\"info\",\n",
    "        )\n",
    "        model.load(checkpoint_path, device=device)\n",
    "        log_or_print(\n",
    "            f\"running predict method of {model_name}\", logger=logger, level=\"info\"\n",
    "        )\n",
    "        pred_dict = model.predict(pred_data=pred_data, device=device)\n",
    "\n",
    "        # ----------------  converting to annotations ------------------------------------------------------------------\n",
    "        progress_bar = tqdm(pred_data)\n",
    "\n",
    "        annots = []\n",
    "        log_or_print(\n",
    "            \"converting predictions to annotations\", logger=logger, level=\"info\"\n",
    "        )\n",
    "        for ind, batch in enumerate(progress_bar):\n",
    "            padding_mask, spect_path = batch[\"padding_mask\"], batch[\"spect_path\"]\n",
    "            padding_mask = np.squeeze(padding_mask)\n",
    "            if isinstance(spect_path, list) and len(spect_path) == 1:\n",
    "                spect_path = spect_path[0]\n",
    "            y_pred = pred_dict[spect_path]\n",
    "\n",
    "            y_pred = torch.argmax(y_pred, dim=1)  # assumes class dimension is 1\n",
    "            y_pred = torch.flatten(y_pred).cpu().numpy()[padding_mask]\n",
    "\n",
    "            spect_dict = files.spect.load(spect_path)\n",
    "            t = spect_dict[timebins_key]\n",
    "            labels, onsets_s, offsets_s = labeled_timebins.lbl_tb2segments(\n",
    "                y_pred,\n",
    "                labelmap=labelmap,\n",
    "                t=t,\n",
    "                min_segment_dur=min_segment_dur,\n",
    "                majority_vote=majority_vote,\n",
    "            )\n",
    "            if labels is None and onsets_s is None and offsets_s is None:\n",
    "                # handle the case when all time bins are predicted to be unlabeled\n",
    "                # see https://github.com/NickleDave/vak/issues/383\n",
    "                continue\n",
    "            seq = crowsetta.Sequence.from_keyword(\n",
    "                labels=labels, onsets_s=onsets_s, offsets_s=offsets_s\n",
    "            )\n",
    "\n",
    "            audio_fname = files.spect.find_audio_fname(spect_path)\n",
    "            annot = crowsetta.Annotation(\n",
    "                seq=seq, audio_path=audio_fname, annot_path=annot_csv_path.name\n",
    "            )\n",
    "            annots.append(annot)\n",
    "        \n",
    "    return pred_dict, annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680652df-3e45-4c5d-a117-4c9347360914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cli(toml_path):\n",
    "    toml_path = Path(toml_path)\n",
    "    cfg = config.parse.from_toml_path(toml_path)\n",
    "\n",
    "    if cfg.predict is None:\n",
    "        raise ValueError(\n",
    "            f\"predict called with a config.toml file that does not have a PREDICT section: {toml_path}\"\n",
    "        )\n",
    "\n",
    "    # ---- set up logging ----------------------------------------------------------------------------------------------\n",
    "    timenow = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "\n",
    "    model_config_map = config.models.map_from_path(toml_path, cfg.predict.models)\n",
    "\n",
    "    pred_dict, annots = predict_core(\n",
    "        csv_path=cfg.predict.csv_path,\n",
    "        checkpoint_path=cfg.predict.checkpoint_path,\n",
    "        labelmap_path=cfg.predict.labelmap_path,\n",
    "        model_config_map=model_config_map,\n",
    "        window_size=cfg.dataloader.window_size,\n",
    "        num_workers=cfg.predict.num_workers,\n",
    "        spect_key=cfg.spect_params.spect_key,\n",
    "        timebins_key=cfg.spect_params.timebins_key,\n",
    "        spect_scaler_path=cfg.predict.spect_scaler_path,\n",
    "        device=cfg.predict.device,\n",
    "        annot_csv_filename=cfg.predict.annot_csv_filename,\n",
    "        min_segment_dur=cfg.predict.min_segment_dur,\n",
    "        majority_vote=cfg.predict.majority_vote,\n",
    "        save_net_outputs=cfg.predict.save_net_outputs,\n",
    "        logger=None,\n",
    "    )\n",
    "\n",
    "    return pred_dict, annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c67f57a8-8425-4b2e-805d-8601379ea88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "toml_path = '/home/bart/Documents/repos/coding/birdsong/tweetynet/article/data/configs/Bengalese_Finches/gy60r6_predict_032612.toml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dbdeffd-7aed-43e5-a5d9-36a3f8b73500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bart/Documents/repos/coding/birdsong/tweetynet/article\n"
     ]
    }
   ],
   "source": [
    "cd /home/bart/Documents/repos/coding/birdsong/tweetynet/article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58b3576e-299b-4955-9229-651e5764b633",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "Value specified for data_dir of <class 'vak.config.prep.PrepConfig'> not recognized as a directory:\n/home/bart/Documents/data/BFSongRepository/gy6or6/032612/has_notmat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_dict, annots \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_cli\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoml_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mpredict_cli\u001b[0;34m(toml_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_cli\u001b[39m(toml_path):\n\u001b[1;32m      2\u001b[0m     toml_path \u001b[38;5;241m=\u001b[39m Path(toml_path)\n\u001b[0;32m----> 3\u001b[0m     cfg \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_toml_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoml_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mpredict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict called with a config.toml file that does not have a PREDICT section: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoml_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/tweetygif/lib/python3.8/site-packages/vak/config/parse.py:200\u001b[0m, in \u001b[0;36mfrom_toml_path\u001b[0;34m(toml_path, sections)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m\"\"\"parse a TOML configuration file\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m    sections in a config.toml file.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    199\u001b[0m config_toml \u001b[38;5;241m=\u001b[39m _load_toml_from_path(toml_path)\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_toml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_toml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoml_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msections\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tweetygif/lib/python3.8/site-packages/vak/config/parse.py:150\u001b[0m, in \u001b[0;36mfrom_toml\u001b[0;34m(config_toml, toml_path, sections)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m section_name \u001b[38;5;129;01min\u001b[39;00m config_toml:\n\u001b[1;32m    149\u001b[0m         are_options_valid(config_toml, section_name, toml_path)\n\u001b[0;32m--> 150\u001b[0m         config_dict[section_name\u001b[38;5;241m.\u001b[39mlower()] \u001b[38;5;241m=\u001b[39m \u001b[43mparse_config_section\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig_toml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msection_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoml_path\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Config(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_dict)\n",
      "File \u001b[0;32m~/anaconda3/envs/tweetygif/lib/python3.8/site-packages/vak/config/parse.py:94\u001b[0m, in \u001b[0;36mparse_config_section\u001b[0;34m(config_toml, section_name, toml_path)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 err_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     90\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequired_option\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m option is required but was not found in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msection_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m section of the toml config\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m                 )\n\u001b[1;32m     93\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(err_msg)\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSECTION_CLASSES\u001b[49m\u001b[43m[\u001b[49m\u001b[43msection_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msection\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<attrs generated init vak.config.prep.PrepConfig>:14\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, output_dir, audio_format, spect_format, spect_output_dir, annot_file, annot_format, labelset, train_dur, val_dur, test_dur)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dur \u001b[38;5;241m=\u001b[39m __attr_converter_test_dur(test_dur)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _config\u001b[38;5;241m.\u001b[39m_run_validators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[43m__attr_validator_data_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__attr_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     __attr_validator_output_dir(\u001b[38;5;28mself\u001b[39m, __attr_output_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dir)\n\u001b[1;32m     16\u001b[0m     __attr_validator_audio_format(\u001b[38;5;28mself\u001b[39m, __attr_audio_format, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_format)\n",
      "File \u001b[0;32m~/anaconda3/envs/tweetygif/lib/python3.8/site-packages/vak/config/validators.py:13\u001b[0m, in \u001b[0;36mis_a_directory\u001b[0;34m(instance, attribute, value)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"check if given path is a directory\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(value)\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotADirectoryError\u001b[39;00m(\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue specified for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattribute\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(instance)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not recognized as a directory:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m     )\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: Value specified for data_dir of <class 'vak.config.prep.PrepConfig'> not recognized as a directory:\n/home/bart/Documents/data/BFSongRepository/gy6or6/032612/has_notmat"
     ]
    }
   ],
   "source": [
    "pred_dict, annots = predict_cli(toml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f02e62d4-6358-44d5-9935-e968a3705bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mBird0\u001b[0m/  \u001b[01;34mBird4\u001b[0m/  \u001b[01;34mBird7\u001b[0m/  \u001b[01;34mBird9\u001b[0m/  error_across_birds_with_cleanup.csv\n"
     ]
    }
   ],
   "source": [
    "ls results/Bengalese_Finches/learncurve/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82431fae-e04a-4213-83ec-1d03b4a0f00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'results/Bengalese_Finches/learncurve/gy6or6': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "ls results/Bengalese_Finches/learncurve/gy6or6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "612c66fb-395e-46b6-b9e9-5da04b13fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {k: v.cpu().numpy() for k, v in pred_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "208c513d-c3f2-435f-bbac-8742f1d790f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/bart/Documents/repos/coding/birdsong/tweetynet/article/data/demo-gif/llb3_predict_first_submission_longtrain.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/home/bart/Documents/repos/coding/birdsong/tweetynet/article/data/demo-gif/llb3_predict_first_submission_longtrain.joblib'\n",
    "value = {\n",
    "    'pred_dict': pred_dict,\n",
    "    'annots': annots\n",
    "}\n",
    "joblib.dump(value, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
