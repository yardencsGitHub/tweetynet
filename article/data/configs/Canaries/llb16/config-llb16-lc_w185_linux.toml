[PREP]
labelset = "range: 1-30"
spect_format = "npz"
annot_file = "D:\\Users\\yarde\\vak_project\\llb16\\llb16_annotation_May_2019_alexa_4TF.mat"
annot_format = "yarden"
data_dir = "D:\\Users\\yarde\\vak_project\\llb16\\annotated"
test_dur = 5000
train_dur = 24000
val_dur = 250
output_dir = "D:\\Users\\yarde\\vak_project\\llb16\\train"

[SPECT_PARAMS]
fft_size = 1024
step_size = 64
freq_cutoffs = [ 500, 10000,]
thresh = 6.25

[DATALOADER]
window_size = 185

[LEARNCURVE]
models = "TweetyNet"
train_set_durs = [190, 240, 300, 360, 420, 480, 540, 600, 660,]
num_replicates = 7
normalize_spectrograms = false
batch_size = 8
num_epochs = 1
val_step = 250
patience = 4
ckpt_step = 1000
num_workers = 12
device = "cuda"
root_results_dir = "D:\\Users\\yarde\\vak_project\\llb16\\results"
csv_path = "D:\\Users\\yarde\\vak_project\\llb16\\train\\annotated_prep_200613_135259_linux2_npz.csv"
previous_run_path = "D:\\Users\\yarde\\vak_project\\llb16\\results\\results_200613_145015"

[TweetyNet.optimizer]
lr = 0.001
