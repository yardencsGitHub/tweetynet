from pathlib import Path

import joblib
import pandas as pd

from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.utils.fixes import loguniform
# need to import this for HalvingRandomSearchCV to work!!!
from sklearn.experimental import enable_halving_search_cv
from sklearn.model_selection import HalvingRandomSearchCV
from sklearn.svm import SVC

from tqdm import tqdm


def fit(extract_csv_path,
        learncurve_csv_path,
        split='train'):
    extract_df = pd.read_csv(extract_csv_path)
    learncurve_df = pd.read_csv(learncurve_csv_path)

    # do an INNER JOIN to add 'features_path' from DataFrame saved by extract script
    # to this split of the dataset generated by `learncurve`
    learncurve_df = pd.merge(learncurve_df, extract_df, how='inner')

    ftr_paths = learncurve_df[learncurve_df.split == split].features_path.values.tolist()
    df = []
    for ftr_path in tqdm(ftr_paths):
        df.append(
            pd.read_csv(ftr_path)
        )
    df = pd.concat(df)
    y = df.labels.values
    x = df[df.columns.drop('labels')].values

    tuned_parameters = {
        'svc__kernel': ['rbf'],
        'svc__gamma': loguniform(1e-9, 1e13),
        'svc__C': loguniform(1e-2, 1e10)
    }

    pipe = make_pipeline(StandardScaler(), SVC())
    clf = HalvingRandomSearchCV(
        pipe, tuned_parameters, factor=3, n_jobs=-2, verbose=1,
    )
    clf.fit(x, y)

    return clf


def save_clf(clf,
             csv_path,
             clf_dst):
    csv_path = Path(csv_path)
    clf_fname = f'{csv_path.name}.svm.joblib'
    joblib.dump(clf, clf_dst / clf_fname)
